{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "USER REVIEWS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "# se importan las librerias que se van a usar \n",
    "import gzip\n",
    "import ast\n",
    "import chardet\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se accede a la informacion del archivo comprimido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 25799 entries, 0 to 25798\n",
      "Data columns (total 3 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   user_id   25799 non-null  object\n",
      " 1   user_url  25799 non-null  object\n",
      " 2   reviews   25799 non-null  object\n",
      "dtypes: object(3)\n",
      "memory usage: 604.8+ KB\n"
     ]
    }
   ],
   "source": [
    "file_path_user_reviews = '../datasets/user_reviews.json.gz'\n",
    "lista=[]\n",
    "with gzip.open(file_path_user_reviews, 'rt', encoding='MacRoman') as archivo:\n",
    "    for line in archivo.readlines():\n",
    "        lista.append(ast.literal_eval(line))\n",
    "\n",
    "user_review = pd.DataFrame(lista)\n",
    "user_review.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "se procede a desanidar la columna reviews que se necesitara mas adelante pare el proceso "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "explode_df_user_review = user_review.explode('reviews') # Duplico las filas generando un diccionario "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ahora se concateno el dataframe original, con el dataframe generado \n",
    "explode_df_user_review = pd.concat([explode_df_user_review.drop(['reviews'],axis=1),\n",
    "                                    explode_df_user_review['reviews'].apply(pd.Series)],axis=1)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 59333 entries, 0 to 25798\n",
      "Data columns (total 10 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   user_id      59333 non-null  object \n",
      " 1   user_url     59333 non-null  object \n",
      " 2   funny        59305 non-null  object \n",
      " 3   posted       59305 non-null  object \n",
      " 4   last_edited  59305 non-null  object \n",
      " 5   item_id      59305 non-null  object \n",
      " 6   helpful      59305 non-null  object \n",
      " 7   recommend    59305 non-null  object \n",
      " 8   review       59305 non-null  object \n",
      " 9   0            0 non-null      float64\n",
      "dtypes: float64(1), object(9)\n",
      "memory usage: 5.0+ MB\n"
     ]
    }
   ],
   "source": [
    "explode_df_user_review.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se eliminan las columnas que no se van a usar "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "explode_df_user_review.drop(columns=['user_url','funny','helpful','last_edited', 0],inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se realiza el analisis de sentimiento solicitado con NLP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se va a crear la columna 'sentiment_analysis' aplicando análisis de sentimiento con NLP con la siguiente escala: debe tomar el valor '0' si es malo, '1' si es neutral y '2' si es positivo. Esta nueva columna debe reemplazar la de user_reviews.review para facilitar el trabajo de los modelos de machine learning y el análisis de datos. De no ser posible este análisis por estar ausente la reseña escrita, debe tomar el valor de 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\Willc\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "# Descargar recursos de NLTK \n",
    "nltk.download('vader_lexicon')\n",
    "\n",
    "# Crear una instancia de SentimentIntensityAnalyzer\n",
    "sia = SentimentIntensityAnalyzer()\n",
    "\n",
    "# Crear una función para asignar el análisis de sentimiento\n",
    "def assign_sentiment_analysis(review):\n",
    "    if pd.isna(review):  # Si la reseña está ausente\n",
    "        return 1  # Valor neutral\n",
    "    else:\n",
    "        # Realizar análisis de sentimiento con vaderSentiment\n",
    "        compound_score = sia.polarity_scores(review)['compound']\n",
    "\n",
    "        if compound_score >= 0.05:\n",
    "            return 2  # Positivo\n",
    "        elif compound_score <= -0.05:\n",
    "            return 0  # Negativo\n",
    "        else:\n",
    "            return 1  # Neutral\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "explode_df_user_review['review'].fillna('',inplace=True) # Remplazo los nulos con un string vacio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplicar la función a la columna 'review' y crear la nueva columna 'sentiment_analysis'\n",
    "explode_df_user_review['sentiment_analysis'] = explode_df_user_review['review'].apply(assign_sentiment_analysis)\n",
    "\n",
    "# Reemplazar la columna original 'review' con la nueva 'sentiment_analysis'\n",
    "explode_df_user_review.drop(columns=['review'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verificamos valores nulos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "user_id                0\n",
       "posted                28\n",
       "item_id               28\n",
       "recommend             28\n",
       "sentiment_analysis     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 283,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "explode_df_user_review.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>posted</th>\n",
       "      <th>item_id</th>\n",
       "      <th>recommend</th>\n",
       "      <th>sentiment_analysis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>gdxsd</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>76561198094224872</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1047</th>\n",
       "      <td>76561198021575394</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3954</th>\n",
       "      <td>cmuir37</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5394</th>\n",
       "      <td>Jaysteeny</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6135</th>\n",
       "      <td>ML8989</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7583</th>\n",
       "      <td>76561198079215291</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7952</th>\n",
       "      <td>76561198079342142</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9894</th>\n",
       "      <td>76561198061996985</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10381</th>\n",
       "      <td>76561198108286351</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10560</th>\n",
       "      <td>CallTripleZero</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11316</th>\n",
       "      <td>Priceless612</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11320</th>\n",
       "      <td>diabolical666</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11549</th>\n",
       "      <td>DrScottnik</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12865</th>\n",
       "      <td>76561198110176420</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13242</th>\n",
       "      <td>jojoPL1987</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13698</th>\n",
       "      <td>Kylee_Kylie</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15949</th>\n",
       "      <td>_samie</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15990</th>\n",
       "      <td>FifthExclamation</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16013</th>\n",
       "      <td>sbenji</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16546</th>\n",
       "      <td>SpatialWheel14</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17022</th>\n",
       "      <td>76561198065238937</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18201</th>\n",
       "      <td>76561198071075080</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21386</th>\n",
       "      <td>76561198063489150</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22705</th>\n",
       "      <td>thecommunistbear</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23785</th>\n",
       "      <td>76561198085883839</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24911</th>\n",
       "      <td>76561198100396147</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25001</th>\n",
       "      <td>76561198102423654</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 user_id posted item_id recommend  sentiment_analysis\n",
       "62                 gdxsd    NaN     NaN       NaN                   1\n",
       "83     76561198094224872    NaN     NaN       NaN                   1\n",
       "1047   76561198021575394    NaN     NaN       NaN                   1\n",
       "3954             cmuir37    NaN     NaN       NaN                   1\n",
       "5394           Jaysteeny    NaN     NaN       NaN                   1\n",
       "6135              ML8989    NaN     NaN       NaN                   1\n",
       "7583   76561198079215291    NaN     NaN       NaN                   1\n",
       "7952   76561198079342142    NaN     NaN       NaN                   1\n",
       "9894   76561198061996985    NaN     NaN       NaN                   1\n",
       "10381  76561198108286351    NaN     NaN       NaN                   1\n",
       "10560     CallTripleZero    NaN     NaN       NaN                   1\n",
       "11316       Priceless612    NaN     NaN       NaN                   1\n",
       "11320      diabolical666    NaN     NaN       NaN                   1\n",
       "11549         DrScottnik    NaN     NaN       NaN                   1\n",
       "12865  76561198110176420    NaN     NaN       NaN                   1\n",
       "13242         jojoPL1987    NaN     NaN       NaN                   1\n",
       "13698        Kylee_Kylie    NaN     NaN       NaN                   1\n",
       "15949             _samie    NaN     NaN       NaN                   1\n",
       "15990   FifthExclamation    NaN     NaN       NaN                   1\n",
       "16013             sbenji    NaN     NaN       NaN                   1\n",
       "16546     SpatialWheel14    NaN     NaN       NaN                   1\n",
       "17022  76561198065238937    NaN     NaN       NaN                   1\n",
       "18201  76561198071075080    NaN     NaN       NaN                   1\n",
       "21386  76561198063489150    NaN     NaN       NaN                   1\n",
       "22705   thecommunistbear    NaN     NaN       NaN                   1\n",
       "23785  76561198085883839    NaN     NaN       NaN                   1\n",
       "24911  76561198100396147    NaN     NaN       NaN                   1\n",
       "25001  76561198102423654    NaN     NaN       NaN                   1"
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "explode_df_user_review[explode_df_user_review.isnull().any(axis=1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ya que las filas estan completamente vacias se procede a eliminarlas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "explode_df_user_review.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>posted</th>\n",
       "      <th>item_id</th>\n",
       "      <th>recommend</th>\n",
       "      <th>sentiment_analysis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>76561197970982479</td>\n",
       "      <td>Posted November 5, 2011.</td>\n",
       "      <td>1250</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>76561197970982479</td>\n",
       "      <td>Posted July 15, 2011.</td>\n",
       "      <td>22200</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>76561197970982479</td>\n",
       "      <td>Posted April 21, 2011.</td>\n",
       "      <td>43110</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>js41637</td>\n",
       "      <td>Posted June 24, 2014.</td>\n",
       "      <td>251610</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>js41637</td>\n",
       "      <td>Posted September 8, 2013.</td>\n",
       "      <td>227300</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             user_id                     posted item_id recommend  \\\n",
       "0  76561197970982479   Posted November 5, 2011.    1250      True   \n",
       "0  76561197970982479      Posted July 15, 2011.   22200      True   \n",
       "0  76561197970982479     Posted April 21, 2011.   43110      True   \n",
       "1            js41637      Posted June 24, 2014.  251610      True   \n",
       "1            js41637  Posted September 8, 2013.  227300      True   \n",
       "\n",
       "   sentiment_analysis  \n",
       "0                   2  \n",
       "0                   2  \n",
       "0                   2  \n",
       "1                   2  \n",
       "1                   2  "
      ]
     },
     "execution_count": 286,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "explode_df_user_review.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "verificamos los datos duplicados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "user_id               874\n",
       "posted                874\n",
       "item_id               874\n",
       "recommend             874\n",
       "sentiment_analysis    874\n",
       "dtype: int64"
      ]
     },
     "execution_count": 287,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "explode_df_user_review[explode_df_user_review.duplicated()].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eliminamos las filas duplicadas ya que no nos aportan a nuestro analisis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "explode_df_user_review = explode_df_user_review.drop_duplicates()#eliminamos las filas duplicadas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "se procede a eliminar las columnas que no son necesarias para el procedimiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(58431, 5)"
      ]
     },
     "execution_count": 289,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "explode_df_user_review.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 58431 entries, 0 to 25798\n",
      "Data columns (total 5 columns):\n",
      " #   Column              Non-Null Count  Dtype \n",
      "---  ------              --------------  ----- \n",
      " 0   user_id             58431 non-null  object\n",
      " 1   posted              58431 non-null  object\n",
      " 2   item_id             58431 non-null  object\n",
      " 3   recommend           58431 non-null  object\n",
      " 4   sentiment_analysis  58431 non-null  int64 \n",
      "dtypes: int64(1), object(4)\n",
      "memory usage: 2.7+ MB\n"
     ]
    }
   ],
   "source": [
    "explode_df_user_review.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se identifica que para la funcion 3 se debe crear la columna year con los años de posted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    "explode_df_user_review['year'] = explode_df_user_review['posted'].str.extract(r'(\\d{4})')#estrae de la columna posted 4 digitos seguidos que corresponden al año"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "user_id                  0\n",
       "posted                   0\n",
       "item_id                  0\n",
       "recommend                0\n",
       "sentiment_analysis       0\n",
       "year                  9933\n",
       "dtype: int64"
      ]
     },
     "execution_count": 298,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "explode_df_user_review.isnull().sum()#verificamos los valores nulos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ya que estas filas nulas en la columna year contiene casi toda la informacion menos el año, no se eliminaran pero se fitraran para ciertas funciones en las que se use la columna year"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por ultimo despuesde de haber realizado las transformaciones solicitadas y las que se consideraron necesarias se procede a exportar a un csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [],
   "source": [
    "explode_df_user_review.to_csv('../datasets/user_review.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Entorno",
   "language": "python",
   "name": "entorno"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
